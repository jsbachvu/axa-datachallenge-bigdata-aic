{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import matplotlib.pyplot as plt\n",
    "# from __future__ import unicode_literals\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_csv_number.to_csv('./data/train_data_number.csv', sep=',', index=False)\n",
    "data_csv_number = pd.read_csv('./data_train_final.csv')\n",
    "uni_ass = np.unique(data_csv_number['ASS_ASSIGNMENT'])\n",
    "print data_csv_number.keys()\n",
    "print uni_ass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_csv_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subdata = dict()\n",
    "for ass in uni_ass:\n",
    "    subdata[ass] = data_csv_number[data_csv_number['ASS_ASSIGNMENT'] == ass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subdata['CMS'].drop(['ASS_ASSIGNMENT','prediction', 'DATE', 'hour', 'minute'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subdata['Téléphonie']['prediction'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create training data \n",
    "X = dict()\n",
    "Y = dict()\n",
    "\n",
    "for ass in uni_ass:\n",
    "    X[ass] = subdata[ass].drop(['ASS_ASSIGNMENT','prediction', 'DATE', 'hour', 'minute'], axis=1).values\n",
    "    Y[ass] = subdata[ass]['prediction'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tuning params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.decomposition import PCA                                            \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linExLoss(y, y_pred):\n",
    "    result = 0;\n",
    "    alpha = 0.1\n",
    "    for yt,yp in zip(y,y_pred):\n",
    "        tehta = alpha*(yt-yp)\n",
    "        result += np.exp(tehta)-tehta-1\n",
    "    return result/len(y)\n",
    "\n",
    "def newScore(y, y_pred):\n",
    "    return 1/linExLoss(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_params = []\n",
    "\n",
    "for ass in uni_ass:\n",
    "    \n",
    "    print (\"++++++++++++ \",ass)\n",
    "#     model_p = SVR(C=2.0, epsilon=0.2)\n",
    "#     model_p = SVR(C=2.0, epsilon=0.4)\n",
    "    \n",
    "#     model_p =  GradientBoostingRegressor(              \n",
    "#                     n_estimators=300,                              \n",
    "#                     learning_rate=0.2,                            \n",
    "#                     random_state=422)\n",
    "#     model_p = Pipeline([                                      \n",
    "#                     ('pca', PCA(n_components=self.n_components)),                    \n",
    "#                     ('reg', GradientBoostingRegressor(                               \n",
    "#                         n_estimators=300,                              \n",
    "#                         learning_rate=0.2,                            \n",
    "#                         random_state=42))                                            \n",
    "#                 ])\n",
    "#     model_p = RandomForestRegressor(n_estimators=300, max_depth=3, random_state=2)\n",
    "\n",
    "    rfc = RandomForestRegressor(random_state=23)\n",
    "    param_grid = { \n",
    "        'n_estimators' : range(100,300,50),#[50, 100, 150, 200],\n",
    "        'max_depth' : [1,2,3]\n",
    "    }\n",
    "    model_p = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=6, scoring=newScore)\n",
    "    model_p.fit(X[ass], Y[ass])\n",
    "    best_params.append(model_p.best_params_)\n",
    "    print model_p\n",
    "    print model_p.best_score_\n",
    "    print model_p.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
